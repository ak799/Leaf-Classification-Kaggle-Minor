{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the implementation of CNN, we have used keras library on top of tensor flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image Preprocessing**\n",
    "\n",
    "Loading the images converting them to array and rotating the images and appending them to the same array so as to bring uniformity in the data, i.e. trying to eliminate the problem of different orientations etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from matplotlib import pyplot as plt\n",
    "path = \"code/images/\"\n",
    "images_arr = []\n",
    "\n",
    "\n",
    "for i in range(1584):\n",
    "    img_path = path + str(i+1) + '.jpg'\n",
    "    \n",
    "    img = image.load_img(img_path, color_mode='grayscale', target_size=(50,50))\n",
    "    img_arr = image.img_to_array(img)\n",
    "    tmp = np.zeros(img_arr.shape)\n",
    "    tmp += img_arr\n",
    "    theta = 22.5\n",
    "    while theta < 360:\n",
    "        img_arr = image.apply_affine_transform(img_arr, theta=theta)\n",
    "        tmp += img_arr\n",
    "        theta += 22.5\n",
    "    tmp = tmp.astype('float32')\n",
    "    tmp /= (360/22.5)\n",
    "    images_arr.append(tmp/255)\n",
    "    \n",
    "plt.imshow(image.array_to_img(images_arr[8]))\n",
    "print(images_arr[8].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numbering the species name**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the csv file using pandas framework and assigning unique ids to the names of the species. The dataset consists of 64 x 3 features , along with the species name, id (corresponding to the image) and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                species   margin1   margin2   margin3   margin4  \\\n",
      "0   1            Acer_Opalus  0.007812  0.023438  0.023438  0.003906   \n",
      "1   2  Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625   \n",
      "2   3   Quercus_Hartwissiana  0.005859  0.009766  0.019531  0.007812   \n",
      "3   5        Tilia_Tomentosa  0.000000  0.003906  0.023438  0.005859   \n",
      "4   6     Quercus_Variabilis  0.005859  0.003906  0.048828  0.009766   \n",
      "\n",
      "    margin5   margin6   margin7  margin8  ...  texture55  texture56  \\\n",
      "0  0.011719  0.009766  0.027344      0.0  ...   0.007812   0.000000   \n",
      "1  0.025391  0.001953  0.019531      0.0  ...   0.000977   0.000000   \n",
      "2  0.003906  0.005859  0.068359      0.0  ...   0.154300   0.000000   \n",
      "3  0.021484  0.019531  0.023438      0.0  ...   0.000000   0.000977   \n",
      "4  0.013672  0.015625  0.005859      0.0  ...   0.096680   0.000000   \n",
      "\n",
      "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
      "0   0.002930   0.002930   0.035156        0.0        0.0   0.004883   \n",
      "1   0.000000   0.000977   0.023438        0.0        0.0   0.000977   \n",
      "2   0.005859   0.000977   0.007812        0.0        0.0   0.000000   \n",
      "3   0.000000   0.000000   0.020508        0.0        0.0   0.017578   \n",
      "4   0.021484   0.000000   0.000000        0.0        0.0   0.000000   \n",
      "\n",
      "   texture63  texture64  \n",
      "0   0.000000   0.025391  \n",
      "1   0.039062   0.022461  \n",
      "2   0.020508   0.002930  \n",
      "3   0.000000   0.047852  \n",
      "4   0.000000   0.031250  \n",
      "\n",
      "[5 rows x 194 columns]\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./train.csv')\n",
    "print(data.head())\n",
    "idx = 0\n",
    "name2id = {}\n",
    "for sp in data.species:\n",
    "    if sp not in name2id:\n",
    "        name2id[sp] = idx\n",
    "        idx += 1\n",
    "\n",
    "print(len(name2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "real_data array consists of the features of the dataset\n",
    "\n",
    "real_label array consists of the label of the species\n",
    "\n",
    "real_id consists of the id of the image\n",
    "\n",
    "Now everything is combined to form one single array of x_train and y_train for training purposes\n",
    "\n",
    "x_train_img consists of image training data (3-d array of images)\n",
    "\n",
    "x_train consists of 64x3 features read from the csv file\n",
    "\n",
    "y_train consists of correct output for the image\n",
    "\n",
    "Also converting the y_train and y_test to one hot encoded form for softmax_loss calculation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = []\n",
    "head += ['margin'+str(i+1) for i in range(64)]\n",
    "head += ['shape'+str(i+1) for i in range(64)]\n",
    "head += ['texture'+str(i+1) for i in range(64)]\n",
    "\n",
    "\n",
    "real_data = [[] for i in range(990)]\n",
    "real_label = []\n",
    "real_id = []\n",
    "for i in data.id:\n",
    "    real_id.append(i)\n",
    "for h in head:\n",
    "    for i , val in enumerate(data[h]):\n",
    "        real_data[i].append(val)\n",
    "\n",
    "for label in data.species:\n",
    "    real_label.append(name2id[label])\n",
    "\n",
    "assert(len(real_data) == len(real_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting into train and test data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "x_train_img, x_test_img = [], []\n",
    "\n",
    "for i in range(len(real_data)):\n",
    "    if i % 5 == 0:\n",
    "        x_test_img.append(images_arr[ real_id[i] - 1 ])\n",
    "        x_test.append(real_data[i])\n",
    "        y_test.append(real_label[i])\n",
    "        continue\n",
    "    x_train.append(real_data[i])\n",
    "    x_train_img.append(images_arr[ real_id[i] - 1 ])\n",
    "    y_train.append(real_label[i])\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_train_img = np.array(x_train_img)\n",
    "x_test = np.array(x_test)\n",
    "x_test_img = np.array(x_test_img)\n",
    "y_test = np.array(y_test)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train).astype('float32')\n",
    "y_test = to_categorical(y_test).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printing the shape of the train and test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(792, 192)\n",
      "(198, 192)\n",
      "(198, 99)\n",
      "(792, 99)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network architecture consists of two sets of layers, first the set of convolution layers and maxpooling layers which we have concatenated with the input feature layers and connected further to dense layers. Then we applied the convolution layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_img (InputLayer)          [(None, 50, 50, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 48, 48, 16)   160         input_img[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 24, 48, 16)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 24, 24, 16)   0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 22, 22, 32)   4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 11, 22, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 11, 11, 32)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 9, 9, 32)     9248        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_feat (InputLayer)         [(None, 192)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2592)         0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2784)         0           input_feat[0][0]                 \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1500)         4177500     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1500)         6000        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1000)         1501000     batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1000)         4000        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 500)          500500      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500)          2000        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 115)          57615       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 115)          460         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 99)           11484       batch_normalization_3[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 6,274,607\n",
      "Trainable params: 6,268,377\n",
      "Non-trainable params: 6,230\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(x_train[0])\n",
    "print(input_dim)\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "inp_img = Input(shape=(50,50,1), name='input_img')\n",
    "c1 = Conv2D(16, kernel_size=3, activation='relu')(inp_img) # 48 x 48\n",
    "p1 = MaxPooling2D(pool_size=(2,1))(c1) # 24 x 48\n",
    "p1 = MaxPooling2D(pool_size=(1,2))(p1) # 24 x 24\n",
    "c2 = Conv2D(32, kernel_size=3, activation='relu')(p1) # 22 x 22\n",
    "p2 = MaxPooling2D(pool_size=(2,1))(c2) # 11 x 22\n",
    "p2 = MaxPooling2D(pool_size=(1,2))(p2) # 11 x 11\n",
    "c3 = Conv2D(32, kernel_size=3, activation='relu')(p2) # 9 x 9\n",
    "f1 = Flatten()(c3) # 64 x 9 x 9 x 16\n",
    "\n",
    "inp_feat = Input(shape=(input_dim, ), name='input_feat')\n",
    "x = concatenate([inp_feat, f1])\n",
    "d = Dense(1500, activation='relu')(x)\n",
    "d = BatchNormalization()(d)\n",
    "d = Dense(1000, activation='relu')(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = Dense(500, activation='relu')(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = Dense(115, activation='relu')(d)\n",
    "d = BatchNormalization()(d)\n",
    "out = Dense(99, activation='softmax', name='output')(d)\n",
    "\n",
    "model = Model(inputs=[inp_img, inp_feat], outputs=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 4.0216 - accuracy: 0.1313 - val_loss: 4.6602 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/60\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 2.4514 - accuracy: 0.4672 - val_loss: 4.5937 - val_accuracy: 0.0202\n",
      "Epoch 3/60\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 1.2697 - accuracy: 0.8169 - val_loss: 4.6271 - val_accuracy: 0.0202\n",
      "Epoch 4/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.6086 - accuracy: 0.9343 - val_loss: 4.6404 - val_accuracy: 0.0202\n",
      "Epoch 5/60\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.3047 - accuracy: 0.9811 - val_loss: 4.6483 - val_accuracy: 0.0202\n",
      "Epoch 6/60\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.1736 - accuracy: 0.9912 - val_loss: 4.6763 - val_accuracy: 0.0202\n",
      "Epoch 7/60\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.1022 - accuracy: 0.9937 - val_loss: 4.6960 - val_accuracy: 0.0202\n",
      "Epoch 8/60\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.0675 - accuracy: 0.9987 - val_loss: 4.6970 - val_accuracy: 0.0202\n",
      "Epoch 9/60\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 4.7049 - val_accuracy: 0.0202\n",
      "Epoch 10/60\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0376 - accuracy: 0.9987 - val_loss: 4.6939 - val_accuracy: 0.0455\n",
      "Epoch 11/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 4.6904 - val_accuracy: 0.0455\n",
      "Epoch 12/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 4.6865 - val_accuracy: 0.0455\n",
      "Epoch 13/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 4.6694 - val_accuracy: 0.0455\n",
      "Epoch 14/60\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 4.6405 - val_accuracy: 0.0455\n",
      "Epoch 15/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 4.6002 - val_accuracy: 0.0455\n",
      "Epoch 16/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 4.5619 - val_accuracy: 0.0455\n",
      "Epoch 17/60\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 4.5179 - val_accuracy: 0.0505\n",
      "Epoch 18/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 4.4545 - val_accuracy: 0.0758\n",
      "Epoch 19/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 4.3814 - val_accuracy: 0.0909\n",
      "Epoch 20/60\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 4.3058 - val_accuracy: 0.1414\n",
      "Epoch 21/60\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 4.2351 - val_accuracy: 0.1566\n",
      "Epoch 22/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 4.1092 - val_accuracy: 0.1818\n",
      "Epoch 23/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 3.9824 - val_accuracy: 0.2071\n",
      "Epoch 24/60\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 3.8312 - val_accuracy: 0.2525\n",
      "Epoch 25/60\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 3.6656 - val_accuracy: 0.2828\n",
      "Epoch 26/60\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.4893 - val_accuracy: 0.3030\n",
      "Epoch 27/60\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.2457 - val_accuracy: 0.3232\n",
      "Epoch 28/60\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 3.0682 - val_accuracy: 0.3687\n",
      "Epoch 29/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.8647 - val_accuracy: 0.4040\n",
      "Epoch 30/60\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.4149 - val_accuracy: 0.4949\n",
      "Epoch 31/60\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.5665 - val_accuracy: 0.4495\n",
      "Epoch 32/60\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.9155 - val_accuracy: 0.6010\n",
      "Epoch 33/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.8394 - val_accuracy: 0.6414\n",
      "Epoch 34/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.4095 - val_accuracy: 0.7424\n",
      "Epoch 35/60\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.2376 - val_accuracy: 0.7929\n",
      "Epoch 36/60\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.9886 - val_accuracy: 0.8586\n",
      "Epoch 37/60\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.7932 - val_accuracy: 0.8838\n",
      "Epoch 38/60\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6184 - val_accuracy: 0.9040\n",
      "Epoch 39/60\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4999 - val_accuracy: 0.9293\n",
      "Epoch 40/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4184 - val_accuracy: 0.9343\n",
      "Epoch 41/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.9596\n",
      "Epoch 42/60\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3157 - val_accuracy: 0.9495\n",
      "Epoch 43/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9646\n",
      "Epoch 44/60\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9596\n",
      "Epoch 45/60\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9646\n",
      "Epoch 46/60\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1787 - val_accuracy: 0.9697\n",
      "Epoch 47/60\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9596\n",
      "Epoch 48/60\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1595 - val_accuracy: 0.9646\n",
      "Epoch 49/60\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9596\n",
      "Epoch 50/60\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 0.9646\n",
      "Epoch 51/60\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 0.9596\n",
      "Epoch 52/60\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9747\n",
      "Epoch 53/60\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9596\n",
      "Epoch 54/60\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9697\n",
      "Epoch 55/60\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9747\n",
      "Epoch 56/60\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9697\n",
      "Epoch 57/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9697\n",
      "Epoch 58/60\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9545\n",
      "Epoch 59/60\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9697\n",
      "Epoch 60/60\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f48c861c6d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( {  'input_img' : x_train_img, 'input_feat'  : x_train}, \n",
    "              y_train, epochs = 60, batch_size=50, verbose = 1, \n",
    "              validation_data=({'input_img':x_test_img,\n",
    "              'input_feat':x_test}, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printing the shape of model and test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 192)\n",
      "(2, 99)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "inp = {'input_img' : np.array([x_test_img[0] , x_test_img[1]]), \n",
    "      'input_feat'  : np.array([x_test[0] , x_test[1] ]) }\n",
    "x = model.predict(inp)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leaf",
   "language": "python",
   "name": "leaf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
